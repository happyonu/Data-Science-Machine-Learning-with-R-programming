---
title: "5.3 - Titanic Exercises Part 1"
author: "Anurag - Harvard Data Science Professional"
output:
  html_document: default
  pdf_document: default
---



## **These exercises cover everything you have learned in this course so far. You will use the background information to provided to train a number of different types of models on this dataset.**
### **Background**

The Titanic was a British ocean liner that struck an iceberg and sunk on its maiden voyage in 1912 from the United Kingdom to New York. More than 1,500 of the estimated 2,224 passengers and crew died in the accident, making this one of the largest maritime disasters ever outside of war. The ship carried a wide range of passengers of all ages and both genders, from luxury travelers in first-class to immigrants in the lower classes. However, not all passengers were equally likely to survive the accident. You will use real data about a selection of 891 passengers to predict which passengers survived.

## ** Libaries and data ** ##

```{r, include=TRUE}

library(titanic)    # loads titanic_train data frame
library(caret)
library(tidyverse)
library(rpart)

# 3 significant digits
options(digits = 3)

# clean the data - `titanic_train` is loaded with the titanic package
titanic_clean <- titanic_train %>%
    mutate(Survived = factor(Survived),
           Embarked = factor(Embarked),
           Age = ifelse(is.na(Age), median(Age, na.rm = TRUE), Age), # NA age to median age
           FamilySize = SibSp + Parch + 1) %>%    # count family members
    select(Survived,  Sex, Pclass, Age, Fare, SibSp, Parch, FamilySize, Embarked)
```

### ** Question 1: Training and test sets ** ###
3 points possible (graded)
Split titanic_clean into test and training sets - after running the setup code, it should have 891 rows and 9 variables.

Set the seed to 42, then use the caret package to create a 20% data partition based on the Survived column. Assign the 20% partition to test_set and the remaining 80% partition to train_set.

How many observations are in the training set?
```{r, include=TRUE}
set.seed(42, sample.kind = 'Rounding') # if R version >= 3.6
test_index <- createDataPartition(titanic_clean$Survived, times = 1, p = 0.2, list = FALSE)
train_set <- titanic_clean[-test_index,]
test_set <- titanic_clean[test_index,]
nrow(train_set)
nrow(test_set)
mean(train_set$Survived == 1)
```



<br/>

### **Question 2 Baseline prediction by guessing the outcome**

The simplest prediction method is randomly guessing the outcome without using additional predictors. These methods will help us determine whether our machine learning algorithm performs better than chance. How accurate are two methods of guessing Titanic passenger survival?

Set the seed to 3. For each individual in the test set, randomly guess whether that person survived or not. Assume that each person has an equal chance of surviving or not surviving.

Q: What is the accuracy of this guessing method?

```{r, include=TRUE}
set.seed(3, sample.kind = 'Rounding') # if R version >= 3.6
guess_ <- sample(c(0,1), nrow(test_set), replace = TRUE)
test_set %>% 
    filter(Survived == guess_) %>%
    summarize(n() / nrow(test_set))
# guess with equal probability of survival
#guess <- sample(c(0,1), nrow(test_set), replace = TRUE)
#mean(guess == test_set$Survived)
```

### **Question 3a: Predicting survival by sex**

Use the training set to determine whether members of a given sex were more likely to survive or die. Apply this insight to generate survival predictions on the test set.

```{r, include=TRUE}
train_set %>%
    group_by(Sex) %>%
    summarize(Survived = mean(Survived == 1))
```



### **Question 3b: Predicting survival by sex **

Predict survival using sex on the test set: if the survival rate for a sex is over 0.5, predict survival for all individuals of that sex, and predict death if the survival rate for a sex is under 0.5.
What is the accuracy of this sex-based prediction method on the test set?

```{r, include=TRUE}
test_set %>%
    summarize( (sum(Sex == 'female' & Survived == 1) + sum(Sex == 'male' & Survived == 0)) / n())
```	


### **Question 4a: Predicting survival by passenger class**

In which class(es) (Pclass) were passengers more likely to survive than die?

```{r, include=TRUE}
survival_class <- titanic_clean %>%
    group_by(Pclass) %>%
    summarize(PredictingSurvival = ifelse(mean(Survived == 1) >=0.5, 1, 0))
survival_class
```

### **Question 4b: Predicting survival by passenger class **

Predict survival using passenger class on the test set: predict survival if the survival rate for a class is over 0.5, otherwise predict death.
What is the accuracy of this class-based prediction method on the test set?
```{r, include=TRUE}
test_set %>%
    inner_join(survival_class, by='Pclass') %>%
    summarize(PredictingSurvival = mean(Survived == PredictingSurvival))
```

### **Question 4c: Predicting survival by passenger class **
Group passengers by both sex and passenger class.

Which sex and class combinations were more likely to survive than die?
```{r, include=TRUE}
survival_class <- titanic_clean %>%
    group_by(Sex, Pclass) %>%
    summarize(PredictingSurvival = ifelse(mean(Survived == 1) > 0.5, 1, 0))
survival_class
```


### **Question 4d: Predicting survival by passenger class **
Predict survival using both sex and passenger class on the test set. Predict survival if the survival rate for a sex/class combination is over 0.5, otherwise predict death.
What is the accuracy of this sex- and class-based prediction method on the test set?

```{r, include=TRUE}
test_set %>%
    inner_join(survival_class, by=c('Sex', 'Pclass')) %>%
    summarize(PredictingSurvival = mean(Survived == PredictingSurvival))
```


### **Question 5a Confusion Matrix**

Use the confusionMatrix() function to create confusion matrices for the sex model, class model, and combined sex and class model. You will need to convert predictions and survival status to factors to use this function.
What is the "positive" class used to calculate confusion matrix metrics?

```{r, include=TRUE}
library(broom.mixed)
# Confusion Matrix: sex model
sex_model <- train_set %>%
    group_by(Sex) %>%
    summarize(Survived_predict = ifelse(mean(Survived == 1) > 0.5, 1, 0))
test_set1 <- test_set %>%
    inner_join(sex_model, by = 'Sex')
cm1 <- confusionMatrix(data = factor(test_set1$Survived_predict), reference = factor(test_set1$Survived))
cm1 %>%
    tidy() %>%
    filter(term == 'sensitivity') %>%
    .$estimate
cm1 %>%
    tidy() %>%
    filter(term == 'specificity') %>%
    .$estimate
cm1 %>%
    tidy() %>%
    filter(term == 'balanced_accuracy') %>%
    .$estimate
# Confusion Matrix: class model
class_model <- train_set %>%
    group_by(Pclass) %>%
    summarize(Survived_predict = ifelse(mean(Survived == 1) > 0.5, 1, 0))
test_set2 <- test_set %>%
    inner_join(class_model, by = 'Pclass')
cm2 <- confusionMatrix(data = factor(test_set2$Survived_predict), reference = factor(test_set2$Survived))
cm2 %>%
    tidy() %>%
    filter(term == 'sensitivity') %>%
    .$estimate
cm2 %>%
    tidy() %>%
    filter(term == 'specificity') %>%
    .$estimate
cm2 %>%
    tidy() %>%
    filter(term == 'balanced_accuracy') %>%
    .$estimate
# Confusion Matrix: sex and class model
sex_class_model <- train_set %>%
    group_by(Sex, Pclass) %>%
    summarize(Survived_predict = ifelse(mean(Survived == 1) > 0.5, 1, 0))
test_set3 <- test_set %>%
    inner_join(sex_class_model, by=c('Sex', 'Pclass'))
cm3 <- confusionMatrix(data = factor(test_set3$Survived_predict), reference = factor(test_set3$Survived))
cm3 %>%
    tidy() %>%
    filter(term == 'sensitivity') %>%
    .$estimate
cm3 %>%
    tidy() %>%
    filter(term == 'specificity') %>%
    .$estimate
cm3 %>%
    tidy() %>%
    filter(term == 'balanced_accuracy') %>%
    .$estimate
```

### **Question 5a Confusion Matrix**
What is the maximum value of balanced accuracy?



### **Question 6: F1 Scores**

Use the F_meas() function to calculate ùêπ1 scores for the sex model, class model, and combined sex and class model. You will need to convert predictions to factors to use this function.
Which model has the highest ùêπ1 score?


```{r, include=TRUE}
F_meas(data=factor(test_set1$Survived), reference = factor(test_set1$Survived_predict))
F_meas(data=factor(test_set2$Survived), reference = factor(test_set2$Survived_predict))
F_meas(data=factor(test_set3$Survived), reference = factor(test_set3$Survived_predict))
```   

What is the maximum value of the ùêπ1 score?0.872

### **Question 7 Survival by fare - LDA and QDA **

Set the seed to 1. Train a model using linear discriminant analysis (LDA) with the caret lda method using fare as the only predictor.
What is the accuracy on the test set for the LDA model?

```{r, include=TRUE}
fit_lda <- train(Survived ~ Fare, data = train_set, method = 'lda')
Survived_hat <- predict(fit_lda, test_set)
mean(test_set$Survived == Survived_hat) 
```

Set the seed to 1. Train a model using quadratic discriminant analysis (QDA) with the caret qda method using fare as the only predictor.
What is the accuracy on the test set for the QDA model?

```{r, include=TRUE}
fit_qda <- train(Survived ~ Fare, data = train_set, method = 'qda')
Survived_hat <- predict(fit_qda, test_set)
mean(test_set$Survived == Survived_hat)
```

### **Question 8: Logistic regression models  **
Set the seed to 1. Train a logistic regression model with the caret glm method using age as the only predictor.

What is the accuracy on the test set using age as the only predictor?
```{r, include=TRUE}
fit_logreg_a <- glm(Survived ~ Age, data = train_set, family = 'binomial')
survived_hat_a <- ifelse(predict(fit_logreg_a, test_set) >= 0, 1, 0)
mean(survived_hat_a == test_set$Survived)
```

Set the seed to 1. Train a logistic regression model with the caret glm method using four predictors: sex, class, fare, and age.
What is the accuracy on the test set using these four predictors?
```{r, include=TRUE}
fit_logreg_b <- glm(Survived ~ Sex + Pclass + Fare + Age, data = train_set, family = 'binomial')
survived_hat_b <- ifelse(predict(fit_logreg_b, test_set) >= 0, 1, 0)
mean(survived_hat_b == test_set$Survived)
```

Set the seed to 1. Train a logistic regression model with the caret glm method using all predictors. Ignore warnings about rank-deficient fit.
What is the accuracy on the test set using all predictors?
```{r, include=TRUE}
str(train_set)
fit_logreg_c <- glm(Survived ~ ., data = train_set, family = 'binomial')
survived_hat_c <- ifelse(predict(fit_logreg_c, test_set) >= 0, 1, 0)
mean(survived_hat_c == test_set$Survived)
```

### **Question 9a: kNN model**

Set the seed to 6. Train a kNN model on the training set using the caret train function. Try tuning with k = seq(3, 51, 2).
What is the optimal value of the number of neighbors k?

```{r, include=TRUE}
set.seed(6, sample.kind = "Rounding")
# Method below doesn't give same result as EdX (though it is correct)
# ks <- seq(3,51,2)
# res_knn9a <- sapply(ks, function(k) {
#     fit_knn9a <- knn3(Survived ~ ., data = train_set, k = k)
#     survived_hat <- predict(fit_knn9a, train_set, type = "class") %>% factor(levels = levels(train_set$Survived))
#     cm_test <- confusionMatrix(data = survived_hat, reference = train_set$Survived)
#     cm_test$overall["Accuracy"]
# })
# ks[which.max(res_knn9a)]
# Other method using train function
k <- seq(3,51,2)
fit_knn9a <- train(Survived ~ ., data = train_set, method = "knn", tuneGrid = data.frame(k))
fit_knn9a$bestTune
```
### **Question 9a: kNN model**

Plot the kNN model to investigate the relationship between the number of neighbors and accuracy on the training set.
```{r, include=TRUE}
ggplot(fit_knn9a)
```
### **Question 9a: kNN model**
What is the accuracy of the kNN model on the test set?


```{r, include=TRUE}
survived_hat <- predict(fit_knn9a, test_set) %>% factor(levels = levels(test_set$Survived))
cm_test <- confusionMatrix(data = survived_hat, reference = test_set$Survived)
cm_test$overall["Accuracy"]
```



### **Question 10: Cross-validation **

Set the seed to 8 and train a new kNN model. Instead of the default training control, use 10-fold cross-validation where each partition consists of 10% of the total. Try tuning with k = seq(3, 51, 2).
What is the optimal value of k using cross-validation? 

What is the accuracy on the test set using the cross-validated kNN model?

```{r, include=TRUE}
set.seed(8, sample.kind = "Rounding")
fit_knn10 <- train(Survived ~ ., 
                   data=train_set, 
                   method = "knn",
                   tuneGrid = data.frame(k = seq(3, 51, 2)),
                   trControl = trainControl(method = "cv", number=10, p=0.9))
fit_knn10
survived_hat <- predict(fit_knn10, test_set)
cm_test <- confusionMatrix(data = survived_hat, reference = test_set$Survived)
cm_test$overall["Accuracy"]
```

### **Question 11a: Classification tree model  **

Set the seed to 10. Use caret to train a decision tree with the rpart method. Tune the complexity parameter with cp = seq(0, 0.05, 0.002).
What is the optimal value of the complexity parameter (cp)?

What is the accuracy of the decision tree model on the test set?
```{r, include=TRUE}
set.seed(10, sample.kind = 'Rounding')
fit_rpart11 <- train(Survived ~ ., 
                   data=train_set, 
                   method = "rpart",
                   tuneGrid = data.frame(cp = seq(0, 0.05, 0.002)))
                   
plot(fit_rpart11)
survived_hat <- predict(fit_rpart11, test_set)
cm_test <- confusionMatrix(data = survived_hat, reference = test_set$Survived)
cm_test$overall["Accuracy"]

```

### **Question 11b: Classification tree model**

Inspect the final model and plot the decision tree.
Which variables are used in the decision tree?


```{r, include=TRUE}
fit_rpart11$finalModel
plot(fit_rpart11$finalModel, margin=0.1)
text(fit_rpart11$finalModel, cex = 0.75)
```

### **Question 12: Random forest model **


### **Question 9**

Set the seed to 14. Use the caret train() function with the rf method to train a random forest. Test values of mtry = seq(1:7). Set ntree to 100.
What mtry value maximizes accuracy?

```{r, include=TRUE}
set.seed(14, sample.kind = 'Rounding')
fit12_rf <- train(Survived ~., 
                  data = train_set,
                  method = "rf", 
                  tuneGrid = data.frame(mtry = seq(1, 7)), 
                  ntree = 100)
fit12_rf$bestTune
survived_hat <- predict(fit12_rf, test_set)
mean(survived_hat == test_set$Survived)
varImp(fit12_rf)
```

